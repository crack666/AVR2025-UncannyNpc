# AVR2025-UncannyNpc: OpenAI Realtime NPC Integration
**Interaktive VR-NPCs mit KI-gesteuerter Sprachverarbeitung**

---

## ğŸ“‹ **PrÃ¤sentationsÃ¼bersicht**

### **Slide 1: Projekttitel & Team**
- **Projekttitel**: AVR2025-UncannyNpc
- **Untertitel**: Interactive NPCs with Real-time Voice AI in Unity VR
- **Team**: crack666 & maiossa
- **Repository**: https://github.com/crack666/AVR2025-UncannyNpc
- **Technologie**: Unity 2022.3 + OpenAI Realtime API + Meta Quest 3

---

### **Slide 2: Vision & Problemstellung**
**ğŸ¯ Vision**
Entwicklung immersiver VR-Erlebnisse mit AI-gesteuerten NPCs, die natÃ¼rliche Sprachkonversationen in Echtzeit fÃ¼hren kÃ¶nnen.

**ğŸ” Problemstellung**
- Traditionelle NPCs: Vorgefertigte Dialoge, begrenzte Interaktion
- Uncanny Valley: Wie glaubwÃ¼rdig wirken AI-NPCs auf Nutzer:innen?
- Technische Herausforderung: Gapless Audio Streaming in VR

**ğŸª LÃ¶sung**
Integration von OpenAI's Realtime API mit Unity VR fÃ¼r nahtlose Sprachinteraktion

---

### **Slide 3: Technologie-Stack**
**ğŸ› ï¸ Core Technologies**
- **Engine**: Unity 2022.3 LTS mit XR Interaction Toolkit
- **VR Platform**: Meta Quest 2/3, SteamVR Compatible
- **AI Backend**: OpenAI Realtime API (gpt-4o-realtime-preview)
- **Avatar System**: ReadyPlayerMe + Mixamo Integration
- **Audio**: 24kHz WebSocket Streaming, Zero-gap Playback
- **LipSync**: uLipSync Professional + Custom Fallback System

**ğŸ”§ Key Innovations**
- Thread-safe Audio Pipeline
- VR-optimized UI Components  
- Automated Setup System
- Dual LipSync Implementation

---

### **Slide 4: Architektur-Ãœbersicht**
```
ğŸ® Unity VR Interface
        â†“
ğŸ¤– NPCController (State Management)
        â†“
ğŸŒ RealtimeClient (WebSocket zu OpenAI)
        â†“
ğŸµ RealtimeAudioManager (Gapless Streaming)
        â†“
ğŸ­ LipSync System (uLipSync/Fallback)
        â†“
ğŸ‘¤ ReadyPlayerMe Avatar (Animation)
```

**ğŸ“Š Performance Targets**
- Audio Latency: < 1000ms End-to-End
- VR Frame Rate: 72/90 FPS (Quest 2/3)
- Zero audible gaps in audio stream
- Memory Usage: < 50MB fÃ¼r Audio-Buffers

---

### **Slide 5: Key Features - Audio System**
**ğŸ—£ï¸ Gapless Voice Streaming**
- Server-side VAD (Voice Activity Detection)
- PCM16 â†’ Float32 Real-time Konvertierung
- Queue-basierte Buffer-Management (1024 Samples/Buffer)
- Stream End Detection mit intelligenter Silence-Timeout

**ğŸ›ï¸ Professional Voice Selection**
- 8 OpenAI Voices: Alloy, Ash, Ballad, Coral, Echo, Sage, Shimmer, Verse
- Runtime Voice Switching wÃ¤hrend aktiver Sessions
- VR-optimierte Voice Selection UI
---

### **Slide 6: Key Features - VR Integration**
**ğŸ­ Avatar & Animation**
- ReadyPlayerMe Photorealistic Avatars
- State-driven Animation System (Idle, Listening, Speaking, Error)
- Professional LipSync mit uLipSync MFCC-Analyse
- Fallback-System fÃ¼r Basic Mouth Animation

**ğŸ”§ Developer Experience**
- Ein-Klick Automated Setup
- Audio Diagnostics Suite
- Canvas Interaction Fix Tools
- Comprehensive Troubleshooting Guides

**ğŸ¥½ VR/XR Optimierung**
- WorldSpace Canvas fÃ¼r natÃ¼rliche VR-Interaktion
- XR Ray Interactor Support
- Quest 3 Controller KompatibilitÃ¤t
---

### **Slide 7: Implementierte Funktionen**
**âœ… Fertige Core Features**
- Gapless Audio Streaming System
- Dual LipSync Implementation (Professional + Fallback)
- Complete VR/XR Integration
- Automated Project Setup
- 8-Voice Selection System
- ReadyPlayerMe Avatar Support
- Error Handling & Reconnection Logic
- Developer Troubleshooting Suite

**ğŸ”„ Testing & Optimization**
- Performance Optimization
- User Experience Testing
- Bug Fixes & Stability Improvements
- Documentation Completion

**ğŸ“… Research Phase (Geplant)**
- Uncanny Valley Studies
- User Acceptance Testing
- Data Collection & Analysis

---

### **Slide 8: Ausblick & Forschungsaspekte**
**ğŸ”¬ Uncanny Valley Investigation**
- **Hypothese**: Avatar-Stil und Stimme beeinflussen wahrgenommene GlaubwÃ¼rdigkeit
- **Variablen**: 
  - Visuelle Darstellung (Low-Poly â†’ Fotorealistisch)
  - Stimme (8 verschiedene AI-Voices)
  - DialogqualitÃ¤t (NLP Performance)
- **Messung**: 5-Punkt-Likert-Skala fÃ¼r GlaubwÃ¼rdigkeit

**ğŸ“Š Planned Data Collection**
- Minimum 20 Teilnehmer:innen fÃ¼r statistische Signifikanz
- A/B Testing verschiedener Konfigurationen
- Qualitative Post-Experience Interviews
- Privacy-konforme Interaktionsdaten

**ğŸ¯ Expected Insights**
- Optimal Avatar-Voice Combinations
- VR Presence Impact Factors
- Technical Performance vs. User Experience Correlation

---

### **Slide 9: Meilensteine & Zeitplan**
**Phase 1: Core Development âœ… (Mai 2025)**
- OpenAI Realtime API Integration
- Basic Audio Streaming
- Unity Project Structure

**Phase 2: Audio & Animation âœ… (Juni 2025)**
- Gapless Audio Optimization  
- LipSync System Implementation
- ReadyPlayerMe Integration

**Phase 3: VR Optimization âœ… (Juli 2025)**
- XR Toolkit Integration
- Quest Compatibility
- VR UI Components

**Phase 4: Developer Experience âœ… (Juli 2025)**
- Automated Setup System
- Diagnostics & Troubleshooting
- Complete Documentation

**Phase 5: Research & Evaluation ğŸ”„ (ZukÃ¼nftig)**
- User Studies, Data Collection, Analysis

---

### **Slide 10: Demo & Use Cases**
**ğŸ® Interactive Demo**
- Live VR Conversation mit AI-NPC
- Voice Selection in Real-time
- LipSync Animation Showcase
- Error Recovery Demonstration

**ğŸ¯ Anwendungsbereiche**
- **Gaming**: Immersive RPG Characters
- **Education**: Virtual Teaching Assistants  
- **Training**: Professional Coaching NPCs
- **Healthcare**: Therapy & Counseling Applications
- **Research**: Human-AI Interaction Studies
---

*PrÃ¤sentation erstellt fÃ¼r: AVR2025 Projekt*  
*Zielgruppe: Akademisch/Technisch*  
*Empfohlene PrÃ¤sentationsdauer: 15-20 Minuten + Q&A*
